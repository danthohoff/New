# --- 1) Halte + PÜ-Flag ------------------------------------------------------
df_halte = (
    df_zlm
    .filter(pl.col("fsStatus").is_in([1, 3]))
    .with_columns((pl.col("vsp") < ontime_threshold_sec).alias("puenktlich"))
    .select(["Betriebstag", "_ZN", "istzeit_dt", "vsp", "puenktlich"])
)

# --- 2) Linien-Join (matched) ------------------------------------------------
df_line = (
    df_halte
    .join(map_df, left_on="_ZN", right_on="_ZN_MAP", how="inner")
    .select(["Betriebstag", "Linie", "_ZN", "istzeit_dt", "vsp", "puenktlich"])
)

# --- 3) Aggregation pro Tag & Linie -----------------------------------------
per_day_line = (
    df_line
    .group_by(["Betriebstag", "Linie"])
    .agg([
        pl.len().alias("Halte"),
        pl.col("puenktlich").sum().cast(pl.Int64).alias("pü Halte"),
        (pl.col("puenktlich").sum() / pl.len()).alias("PÜ-Quote"),
        pl.col("vsp").median().alias("Median vsp"),
        pl.col("_ZN").n_unique().alias("N Züge (distinct)"),
    ])
    .with_columns(pl.col("Betriebstag").dt.week().alias("KW"))
    .sort(["Betriebstag", "Linie"])
)

# >>> Ab hier NICHTS an per_day_line mehr .select(...)'en! <<<

# --- 4) UNMATCHED (distinct ZN pro Tag ohne Linien-Match) --------------------
# 4a) Basis: alle Halte-Züge (distinct)
halte_zn_per_day = df_halte.select(["Betriebstag", "_ZN"]).unique()

# 4b) Mapping-Schlüssel isolieren (nur _ZN_MAP)
map_keys = map_df.select(["_ZN_MAP"]).unique()

# 4c) Anti-Join => ZN ohne Linie
unmatched = halte_zn_per_day.join(map_keys, left_on="_ZN", right_on="_ZN_MAP", how="anti")
# jetzt hat 'unmatched' NUR die Spalten ['Betriebstag','_ZN'] – das ist gewollt

# 4d) Counts je Tag
unmatched_count_df = (
    unmatched
    .group_by("Betriebstag")
    .agg(pl.col("_ZN").n_unique().alias("Unmatched Züge (distinct)"))
)

# 4e) Gekappte Liste je Tag (versionssicher, ohne arr.*)
unmatched_sorted_cap = (
    unmatched
    .unique()
    .sort(["Betriebstag", "_ZN"])
    .with_columns(pl.row_number().over("Betriebstag").alias("rn"))
    .filter(pl.col("rn") < unmatched_list_cap)
    .group_by("Betriebstag")
    .agg(pl.col("_ZN").implode().alias("_zn_list"))
    .with_columns(
        pl.col("_zn_list").map_elements(lambda lst: ", ".join(lst) if lst else "").alias("Unmatched Züge Liste")
    )
    .drop("_zn_list")
)

# 4f) Zusammenführen der Unmatched-Infos (nur Betriebstag + 2 Spalten)
unmatched_per_day = unmatched_count_df.join(unmatched_sorted_cap, on="Betriebstag", how="left")

# (Optional) Detail-CSV mit allen Unmatched:
# unmatched.sort(["Betriebstag","_ZN"]).write_csv(cache_dir / f"{cfg_key}_unmatched_detail.csv")

# --- 5) Finale Zusammenführung (wichtig: per_day_line ist die linke Seite) ---
per_day = (
    per_day_line
    .join(unmatched_per_day, on="Betriebstag", how="left")
    .with_columns([
        pl.col("Unmatched Züge (distinct)").fill_null(0),
        pl.col("Unmatched Züge Liste").fill_null(""),
    ])
)

# --- 6) Speichern & zurück ---------------------------------------------------
per_day.write_csv(cache_file)
return per_day