import polars as pl

def interactions_nrw_at_stations_efficient(
    df_zlm: pl.DataFrame,
    nrw_bsts: list[str],
    window_minutes: int = 10,
    split_nrw_state: bool = True,
    bin_minutes: int = 1,
) -> pl.DataFrame:
    """
    Speicher- und laufzeiteffiziente Interaktionszählung je Betriebsstelle.
    Vermeidet Self-Joins; arbeitet mit Minutengitter, kumulativen Summen und asof-Alignments.

    Rückgabe: DataFrame je BST mit Spalten:
      - inter_NRWs, inter_NichtNRWs, inter_gemischt
      - (optional) inter_gemischt_fromNRW, inter_gemischt_enterLater
    """

    # --- 0) Minimale Spalten & NRW-Flags je Event ---
    ev = (
        df_zlm
        .select(["Betriebstag", "zn", "bst", "istzeit_dt"])
        .with_columns([
            pl.col("bst").is_in(nrw_bsts).alias("in_nrw"),
        ])
        .sort(["Betriebstag", "zn", "istzeit_dt"])
        .with_columns([
            # Zug ist NRW-Zug, wenn irgendwo im Lauf eine NRW-BST existiert
            pl.col("in_nrw").any().over(["Betriebstag","zn"]).alias("is_nrw_train"),
            # Historie/Zukunft relativ zu dieser Eventzeit (für optionale Aufspaltung)
            pl.col("in_nrw").cum_max().over(["Betriebstag","zn"]).shift(1).fill_null(False).alias("past_in_nrw"),
            pl.col("in_nrw").reverse().cum_max().reverse().over(["Betriebstag","zn"]).shift(-1).fill_null(False).alias("future_in_nrw"),
            pl.when(pl.col("is_nrw_train")).then(pl.lit("NRW")).otherwise(pl.lit("Nicht-NRW")).alias("train_type"),
            # Zeit-Binning (Minute; kann via bin_minutes geändert werden)
            pl.col("istzeit_dt").dt.truncate(f"{bin_minutes}m").alias("t_bin"),
        ])
    )

    # --- 1) Zählung je (Tag, BST, t_bin) ---
    # Basis-Counts
    counts = (
        ev.group_by(["Betriebstag","bst","t_bin"])
          .agg([
              pl.col("train_type").eq("NRW").sum().cast(pl.Int64).alias("n_nrw"),
              pl.col("train_type").ne("NRW").sum().cast(pl.Int64).alias("n_non"),
          ])
    )

    # Optionale Aufspaltung der NRW-Events nach Herkunft/Zukunft
    if split_nrw_state:
        extra = (
            ev.filter(pl.col("train_type")=="NRW")
              .group_by(["Betriebstag","bst","t_bin"])
              .agg([
                  pl.col("past_in_nrw").sum().cast(pl.Int64).alias("n_from"),   # kam schon aus NRW
                  ((~pl.col("past_in_nrw")) & pl.col("future_in_nrw")).sum().cast(pl.Int64).alias("n_enter"),
              ])
        )
        counts = counts.join(extra, on=["Betriebstag","bst","t_bin"], how="left") \
                       .with_columns([
                           pl.col("n_from").fill_null(0),
                           pl.col("n_enter").fill_null(0),
                       ])
    else:
        counts = counts.with_columns([
            pl.lit(0).alias("n_from"),
            pl.lit(0).alias("n_enter"),
        ])

    # --- 2) Kumulative Summen je (Tag, BST) ---
    # Hilfs-Frame mit cumsums
    cs = (
        counts.sort(["Betriebstag","bst","t_bin"])
              .with_columns([
                  pl.col("n_nrw").cum_sum().over(["Betriebstag","bst"]).alias("cs_nrw"),
                  pl.col("n_non").cum_sum().over(["Betriebstag","bst"]).alias("cs_non"),
              ])
    )

    # Zeitfenster-Grenzen
    w = window_minutes
    frame = (
        cs.with_columns([
            (pl.col("t_bin") + pl.duration(minutes=w)).alias("t_upper"),
            (pl.col("t_bin") - pl.duration(minutes=w)).alias("t_lower"),
        ])
    )

    # asof-Helper je Gruppe: cumsum an Ober-/Untergrenze holen
    # right_on t_bin, strategy="backward": letzter Stand <= Zielzeit
    right = cs.select(["Betriebstag","bst","t_bin","cs_nrw","cs_non"])

    # Align upper (≤ t+w)
    up = (
        frame.join_asof(
            right,
            left_on="t_upper", right_on="t_bin",
            by=["Betriebstag","bst"],
            strategy="backward",
            suffix="_up",
        )
        .rename({"cs_nrw":"cs_nrw_up","cs_non":"cs_non_up"})
    )

    # Align lower (≤ t-w-ε): wir nehmen <= (t-w) und ziehen die cumsum ab
    low = (
        frame.join_asof(
            right,
            left_on="t_lower", right_on="t_bin",
            by=["Betriebstag","bst"],
            strategy="backward",
            suffix="_lo",
        )
        .rename({"cs_nrw":"cs_nrw_lo","cs_non":"cs_non_lo"})
    )

    # Merge der Grenzen zurück
    win = (
        frame.join(up.select(["Betriebstag","bst","t_bin","cs_nrw_up","cs_non_up"]),
                   on=["Betriebstag","bst","t_bin"], how="left")
             .join(low.select(["Betriebstag","bst","t_bin","cs_nrw_lo","cs_non_lo"]),
                   on=["Betriebstag","bst","t_bin"], how="left")
             .with_columns([
                 # Fenster-Summen (inkl. aktuelle Minute)
                 (pl.col("cs_nrw_up").fill_null(0) - pl.col("cs_nrw_lo").fill_null(0)).alias("nrw_in_win"),
                 (pl.col("cs_non_up").fill_null(0) - pl.col("cs_non_lo").fill_null(0)).alias("non_in_win"),
             ])
             # cumsum am aktuellen Zeitpunkt (für "after"-Berechnungen)
             .join(cs.select(["Betriebstag","bst","t_bin","cs_nrw","cs_non"]),
                   on=["Betriebstag","bst","t_bin"], how="left")
    )

    # --- 3) Interaktionen berechnen (ohne Paarmaterialisierung) ---
    # Same-type: zähle nur "nach vorn" -> vermeidet Doppelzählung
    win = win.with_columns([
        # wie viele NRW-Ereignisse liegen NACH der aktuellen Minute im Fenster?
        (pl.col("cs_nrw_up").fill_null(0) - pl.col("cs_nrw").fill_null(0)).alias("nrw_after"),
        (pl.col("cs_non_up").fill_null(0) - pl.col("cs_non").fill_null(0)).alias("non_after"),
    ])

    # Beiträge je (Tag, BST, t_bin)
    contrib = (
        win.join(counts.select(["Betriebstag","bst","t_bin","n_nrw","n_non","n_from","n_enter"]),
                 on=["Betriebstag","bst","t_bin"], how="left")
           .with_columns([
               # NRW–NRW: n_nrw(t) * NRWs_nach(t)
               (pl.col("n_nrw").fill_null(0) * pl.col("nrw_after").fill_null(0)).alias("c_NRWs"),
               # Nicht–Nicht: n_non(t) * NONs_nach(t)
               (pl.col("n_non").fill_null(0) * pl.col("non_after").fill_null(0)).alias("c_NichtNRWs"),
               # Gemischt: zähle nur aus Sicht NRW -> n_nrw(t) * ALL_NON_im_Fenster (vor & nach)
               (pl.col("n_nrw").fill_null(0) * pl.col("non_in_win").fill_null(0)).alias("c_gemischt"),
               # optionaler Split
               (pl.col("n_from").fill_null(0) * pl.col("non_in_win").fill_null(0)).alias("c_gemischt_fromNRW"),
               (pl.col("n_enter").fill_null(0) * pl.col("non_in_win").fill_null(0)).alias("c_gemischt_enterLater"),
           ])
    )

    # --- 4) Aggregation pro BST (über alle Tage/Bins aufsummieren) ---
    agg_cols = [
        pl.sum("c_NRWs").alias("inter_NRWs"),
        pl.sum("c_NichtNRWs").alias("inter_NichtNRWs"),
        pl.sum("c_gemischt").alias("inter_gemischt"),
    ]
    if split_nrw_state:
        agg_cols += [
            pl.sum("c_gemischt_fromNRW").alias("inter_gemischt_fromNRW"),
            pl.sum("c_gemischt_enterLater").alias("inter_gemischt_enterLater"),
        ]

    per_bst = (
        contrib.group_by("bst")
               .agg(agg_cols)
               .sort("bst")
    )

    return per_bst