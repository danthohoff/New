def lu_hln_flaeche_per_day(df_ev: pl.DataFrame, trans_net: pl.DataFrame) -> pl.DataFrame:
    """
    Zählt LUs pro Tag nach 'HLN' / 'Fläche' / 'Unbekannt'.
    - dedupliziert LU-Events (standard: (Tag, zn, istzeit_dt, uc))
    - macht Transitionen pro (Tag, zn, end_t) eindeutig
    - mappt per backward, fällt auf forward zurück, sonst 'Unbekannt'
    -> Summe 'LU alle' == klassische LU-Tageszählung.
    """

    # -------- 0) klassische LU-Zählung (zum Abgleich) --------
    classic_daily = (
        df_ev.filter(pl.col("uc").is_not_null())
             .select(["Betriebstag","zn","istzeit_dt","uc"])
             .unique(subset=["Betriebstag","zn","istzeit_dt","uc"])     # <- selbe Dedup-Logik wie unten
             .group_by("Betriebstag").agg(pl.len().alias("LU klassisch"))
    )

    # -------- 1) LU-Events (dedupliziert) --------
    df_lu = (
        df_ev.filter(pl.col("uc").is_not_null())
             .select(["Betriebstag","zn","istzeit_dt","uc"])
             .unique(subset=["Betriebstag","zn","istzeit_dt","uc"])     # wichtig!
             .sort(["Betriebstag","zn","istzeit_dt"])
    )
    if df_lu.is_empty():
        return (
            df_ev.select("Betriebstag").unique().sort("Betriebstag")
                 .with_columns([
                     pl.lit(0).alias("LU HLN"),
                     pl.lit(0).alias("LU Fläche"),
                     pl.lit(0).alias("LU Unbekannt"),
                     pl.lit(0).alias("LU alle"),
                 ])
        )

    # -------- 2) Transitionen (eindeutig je (Tag,zn,end_t)) --------
    # end_t = Zeit am Folgeknoten; falls es doppelte end_t gibt, nehmen wir die "letzte" (keep="last")
    trans_sorted = (
        trans_net
        .rename({"istzeit_dt": "end_t"})
        .sort(["Betriebstag","zn","end_t"])
        .unique(subset=["Betriebstag","zn","end_t"], keep="last")       # <- vermeidet Mehrfachzuordnung
    )

    # -------- 3) asof-Mappings --------
    # 3a backward: letzte Transition mit end_t <= LU-Zeit
    lu_bw = (
        df_lu.join_asof(
            trans_sorted,
            left_on="istzeit_dt", right_on="end_t",
            by=["Betriebstag","zn"],
            strategy="backward",
        )
        .rename({"prev_t":"prev_t_bw","end_t":"end_t_bw","netz":"netz_bw"})
    )
    ok_bw = (pl.col("prev_t_bw").is_not_null()) & (pl.col("istzeit_dt") >= pl.col("prev_t_bw"))

    # 3b forward: erste Transition mit end_t >= LU-Zeit (für LU vor erster Transition)
    lu_fw = (
        df_lu.join_asof(
            trans_sorted,
            left_on="istzeit_dt", right_on="end_t",
            by=["Betriebstag","zn"],
            strategy="forward",
        )
        .rename({"prev_t":"prev_t_fw","end_t":"end_t_fw","netz":"netz_fw"})
    )
    ok_fw = (
        (pl.col("prev_t_fw").is_not_null())
        & (pl.col("istzeit_dt") > pl.col("prev_t_fw"))
        & (pl.col("istzeit_dt") <= pl.col("end_t_fw"))
    )

    # -------- 4) Koaleszieren (pro LU genau 1 Zeile) + Dedup-Guard --------
    lu_mapped = (
        lu_bw.join(
            lu_fw.select(["Betriebstag","zn","istzeit_dt","prev_t_fw","end_t_fw","netz_fw"]),
            on=["Betriebstag","zn","istzeit_dt"],
            how="left",
        )
        .with_columns(
            pl.when(ok_bw).then(pl.col("netz_bw"))
             .when(ok_fw).then(pl.col("netz_fw"))
             .otherwise(pl.lit("Unbekannt"))
             .alias("netz_final")
        )
        .select(["Betriebstag","zn","istzeit_dt","uc","netz_final"])
        # falls der Join wider Erwarten Duplikate erzeugt: hart deduplizieren
        .unique(subset=["Betriebstag","zn","istzeit_dt","uc"])          # <- zweites Netz
    )

    # -------- 5) Tagesweise zählen + Konsistenz sichern --------
    per_day = (
        lu_mapped.group_by(["Betriebstag","netz_final"])
                 .agg(pl.len().alias("n"))
                 .pivot(values="n", index="Betriebstag", columns="netz_final")
    )
    for k in ["HLN","Flaeche","Unbekannt"]:
        if k not in per_day.columns:
            per_day = per_day.with_columns(pl.lit(0).alias(k))

    per_day = (
        per_day.rename({"HLN":"LU HLN","Flaeche":"LU Fläche","Unbekannt":"LU Unbekannt"})
               .with_columns((pl.col("LU HLN")+pl.col("LU Fläche")+pl.col("LU Unbekannt")).alias("LU alle"))
               .sort("Betriebstag")
    )

    # -------- 6) Abgleich mit klassisch (gleiches Dedup wie oben) --------
    per_day = (
        per_day.join(classic_daily, on="Betriebstag", how="left")
               .with_columns(pl.col("LU klassisch").fill_null(0))
               # Wenn du harte Gleichheit willst, prüfe/raise hier:
               # .with_columns( (pl.col("LU alle") - pl.col("LU klassisch")).alias("Delta") )
    )

    return per_day