# analytics_bundle.py
import re
import math
import datetime as dt
from pathlib import Path
import polars as pl

# ======================
# ZLM einlesen (UTF-8)
# ======================
def read_zlm_range(
    root: Path,
    produkt: str,
    tage: list[dt.date],
    *,
    separator=":",
    decimal_comma=True,
    need_cols=("istzeit", "zn", "bst", "fsStatus", "vsp"),
) -> pl.DataFrame:
    files = [
        p for d in tage
        for p in (root / "zlm_lean" / produkt).glob(f"*_{d:%Y%m%d}_*.csv")
    ]
    if not files:
        raise ValueError("Keine zlm-Dateien im Zeitraum gefunden.")

    def _read_one(path: Path) -> pl.DataFrame:
        df = pl.read_csv(
            path, separator=separator, decimal_comma=decimal_comma, infer_schema_length=2000
        )
        df = df.select([c for c in need_cols if c in df.columns])
        casts = []
        if "istzeit" in df.columns:
            casts.append(pl.col("istzeit").str.strptime(pl.Datetime, "%Y-%m-%d %H:%M:%S", strict=False).alias("istzeit_dt"))
        if "zn" in df.columns:
            casts.append(pl.col("zn").cast(pl.Utf8))
        if "bst" in df.columns:
            casts.append(pl.col("bst").cast(pl.Utf8))
        if "fsStatus" in df.columns:
            casts.append(pl.col("fsStatus").cast(pl.Int64, strict=False))
        if "vsp" in df.columns:
            casts.append(pl.col("vsp").cast(pl.Int64, strict=False))
        df = df.with_columns(casts)

        # Betriebstag = erstes Datum im Dateinamen (robust, nur das erste)
        dates = re.findall(r"(\d{8})", str(path))
        if not dates:
            raise ValueError(f"Kann Datum nicht aus Dateinamen parsen: {path}")
        s = dates[0]
        btag = dt.date(int(s[:4]), int(s[4:6]), int(s[6:8]))
        return df.with_columns(pl.lit(btag).alias("Betriebstag"))

    return pl.concat([_read_one(p) for p in files], how="vertical_relaxed")


# =================================
# Selektoren (BST / ZN / Linien)
# =================================
def select_trains_by_bst(df_ev: pl.DataFrame, auswahl_bst: list[str], selection_mode: str = "any") -> pl.DataFrame:
    """gibt (Betriebstag, zn) der betroffenen Züge zurück."""
    auswahl_bst = [str(x).strip() for x in auswahl_bst]
    zlm_on_req = df_ev.filter(pl.col("bst").is_in(auswahl_bst)).select(["Betriebstag", "zn", "bst"])

    if selection_mode == "any":
        return zlm_on_req.select(["Betriebstag", "zn"]).unique()
    if selection_mode == "all":
        cover = zlm_on_req.group_by(["Betriebstag", "zn"]).agg(pl.col("bst").n_unique().alias("covered"))
        return cover.filter(pl.col("covered") == len(set(auswahl_bst))).select(["Betriebstag", "zn"])
    raise ValueError("selection_mode muss 'any' oder 'all' sein")


def select_trains_by_zn(df_ev: pl.DataFrame, zugnummern: list[str]) -> pl.DataFrame:
    zns = [str(z) for z in zugnummern]
    return (
        df_ev.filter(pl.col("zn").is_in(zns))
             .select(["Betriebstag", "zn"])
             .unique()
    )


def load_line_mapping(mapping_csv: Path, zn_col="Zugnummer", line_col="Nr") -> pl.DataFrame:
    return (
        pl.read_csv(mapping_csv)
          .select([zn_col, line_col])
          .with_columns([
              pl.col(zn_col).cast(pl.Utf8).alias("_ZN_MAP"),
              pl.col(line_col).cast(pl.Utf8).alias("Linie"),
          ])
          .select(["_ZN_MAP", "Linie"])
          .unique()
    )


def select_trains_by_line(df_ev: pl.DataFrame, map_df: pl.DataFrame, linien: list[str]) -> pl.DataFrame:
    linien = [str(x) for x in linien]
    # alle (Tag,zn) die im Mapping eine der Linien haben
    trains = (
        df_ev.select(["Betriebstag", "zn"]).unique()
             .with_columns(pl.col("zn").alias("_ZN"))
             .join(map_df, left_on="_ZN", right_on="_ZN_MAP", how="inner")
             .filter(pl.col("Linie").is_in(linien))
             .select(["Betriebstag", "zn"])
             .unique()
    )
    return trains


# =========================================
# Tages-Metriken: (A) Gebiet  vor/auf/nach
# =========================================
def daily_metrics_area(df_ev: pl.DataFrame, selected_trains: pl.DataFrame, *, ontime_sec=360) -> pl.DataFrame:
    """
    Erwartet df_ev mit: Betriebstag, zn, bst, istzeit_dt, fsStatus, vsp
    selected_trains: (Betriebstag, zn) – von select_trains_by_bst(...)

    Liefert Tageswerte inkl. vor/auf/nach (nur für Auswahlzüge) + 'andere'.
    """
    # Fenster (erste/letzte Zeit AUF den Gebiets-BST)
    base = df_ev.join(selected_trains, on=["Betriebstag", "zn"], how="inner")
    ein_aus = (
        base.group_by(["Betriebstag", "zn"])
            .agg([
                pl.col("istzeit_dt").min().alias("einfahrt"),
                pl.col("istzeit_dt").max().alias("ausfahrt"),
            ])
    )

    # Halte (1/3) in Phasen + PÜ + Median vsp
    df_halte = df_ev.filter(pl.col("fsStatus").is_in([1, 3])).select(["Betriebstag", "zn", "istzeit_dt", "vsp"])
    halte_sel = (
        df_halte.join(ein_aus, on=["Betriebstag", "zn"], how="inner")
                .with_columns([
                    pl.when(pl.col("istzeit_dt") < pl.col("einfahrt")).then(pl.lit("vor"))
                     .when(pl.col("istzeit_dt") <= pl.col("ausfahrt")).then(pl.lit("auf"))
                     .otherwise(pl.lit("nach")).alias("phase"),
                    (pl.col("vsp") < ontime_sec).alias("puenktlich"),
                ])
                .group_by(["Betriebstag", "phase"])
                .agg([
                    pl.len().alias("halte"),
                    pl.col("puenktlich").sum().cast(pl.Int64).alias("pue_halte"),
                    pl.col("vsp").median().alias("median_vsp"),
                ])
                .pivot(values=["halte", "pue_halte", "median_vsp"], index="Betriebstag", columns="phase")
    )
    # fehlende Spalten auffüllen
    for base, fill in [("halte", 0), ("pue_halte", 0), ("median_vsp", None)]:
        for ph in ("vor", "auf", "nach"):
            col = f"{base}_{ph}"
            if col not in halte_sel.columns:
                halte_sel = halte_sel.with_columns(pl.lit(fill).alias(col))
    halte_sel = halte_sel.rename({
        "halte_vor": "Halte Auswahl vor", "halte_auf": "Halte Auswahl auf", "halte_nach": "Halte Auswahl nach",
        "pue_halte_vor": "pü Halte Auswahl vor", "pue_halte_auf": "pü Halte Auswahl auf", "pue_halte_nach": "pü Halte Auswahl nach",
        "median_vsp_vor": "Median vsp Auswahl vor", "median_vsp_auf": "Median vsp Auswahl auf", "median_vsp_nach": "Median vsp Auswahl nach",
    })

    # "andere" Halte (nicht in Auswahlzügen)
    df_halte_andere = (
        df_halte.join(selected_trains, on=["Betriebstag", "zn"], how="anti")
                .with_columns((pl.col("vsp") < ontime_sec).alias("puenktlich"))
                .group_by("Betriebstag")
                .agg([
                    pl.len().alias("Halte andere"),
                    pl.col("puenktlich").sum().cast(pl.Int64).alias("pü Halte andere"),
                    pl.col("vsp").median().alias("Median vsp andere"),
                ])
    )

    # Züge (Tageszähler)
    zuege_auswahl_t = selected_trains.group_by("Betriebstag").len().rename({"len": "Züge Auswahl"})
    zuege_andere_t = (
        df_ev.select(["Betriebstag", "zn"]).unique()
             .join(selected_trains, on=["Betriebstag", "zn"], how="anti")
             .group_by("Betriebstag").len().rename({"len": "Züge andere"})
    )

    # Merge pro Tag
    per_day = (
        df_ev.select("Betriebstag").unique().sort("Betriebstag")
             .join(zuege_auswahl_t, on="Betriebstag", how="left")
             .join(zuege_andere_t, on="Betriebstag", how="left")
             .join(halte_sel, on="Betriebstag", how="left")
             .join(df_halte_andere, on="Betriebstag", how="left")
             .with_columns([
                 pl.col("Züge Auswahl").fill_null(0),
                 pl.col("Züge andere").fill_null(0),
                 pl.col("Halte andere").fill_null(0),
                 pl.col("pü Halte andere").fill_null(0),
             ])
             .with_columns((pl.col("Züge Auswahl") + pl.col("Züge andere")).alias("Züge alle"))
             .with_columns(  # Gesamtsummen über Halte
                 (pl.col("Halte Auswahl vor") + pl.col("Halte Auswahl auf") + pl.col("Halte Auswahl nach") + pl.col("Halte andere")).alias("Halte alle"),
             )
             .with_columns(
                 (pl.col("pü Halte Auswahl vor") + pl.col("pü Halte Auswahl auf") + pl.col("pü Halte Auswahl nach") + pl.col("pü Halte andere")).alias("pü Halte alle")
             )
             .with_columns(pl.col("Betriebstag").dt.week().alias("KW"))
    )
    return per_day


# ======================================================
# Tages-Metriken: (B) Zug-/Linienfilter (kein vor/auf/nach)
# ======================================================
def daily_metrics_simple(df_ev: pl.DataFrame, selected_trains: pl.DataFrame, *, ontime_sec=360) -> pl.DataFrame:
    """Auswahl vs Andere – ohne Phasen. Für Filter per ZN oder Linie."""
    df_halte = (
        df_ev.filter(pl.col("fsStatus").is_in([1, 3]))
             .with_columns((pl.col("vsp") < ontime_sec).alias("puenktlich"))
             .select(["Betriebstag", "zn", "vsp", "puenktlich"])
    )
    sel_halte = (
        df_halte.join(selected_trains, on=["Betriebstag", "zn"], how="inner")
                .group_by("Betriebstag")
                .agg([
                    pl.len().alias("Halte Auswahl"),
                    pl.col("puenktlich").sum().cast(pl.Int64).alias("pü Halte Auswahl"),
                    pl.col("vsp").median().alias("Median vsp Auswahl"),
                ])
    )
    andere_halte = (
        df_halte.join(selected_trains, on=["Betriebstag", "zn"], how="anti")
                .group_by("Betriebstag")
                .agg([
                    pl.len().alias("Halte andere"),
                    pl.col("puenktlich").sum().cast(pl.Int64).alias("pü Halte andere"),
                    pl.col("vsp").median().alias("Median vsp andere"),
                ])
    )
    zuege_auswahl_t = selected_trains.group_by("Betriebstag").len().rename({"len": "Züge Auswahl"})
    zuege_andere_t = (
        df_ev.select(["Betriebstag", "zn"]).unique()
             .join(selected_trains, on=["Betriebstag", "zn"], how="anti")
             .group_by("Betriebstag").len().rename({"len": "Züge andere"})
    )

    per_day = (
        df_ev.select("Betriebstag").unique().sort("Betriebstag")
             .join(zuege_auswahl_t, on="Betriebstag", how="left")
             .join(zuege_andere_t, on="Betriebstag", how="left")
             .join(sel_halte, on="Betriebstag", how="left")
             .join(andere_halte, on="Betriebstag", how="left")
             .with_columns([
                 pl.col("Züge Auswahl").fill_null(0),
                 pl.col("Züge andere").fill_null(0),
                 pl.col("Halte Auswahl").fill_null(0),
                 pl.col("pü Halte Auswahl").fill_null(0),
                 pl.col("Halte andere").fill_null(0),
                 pl.col("pü Halte andere").fill_null(0),
             ])
             .with_columns((pl.col("Züge Auswahl") + pl.col("Züge andere")).alias("Züge alle"))
             .with_columns((pl.col("Halte Auswahl") + pl.col("Halte andere")).alias("Halte alle"))
             .with_columns((pl.col("pü Halte Auswahl") + pl.col("pü Halte andere")).alias("pü Halte alle"))
             .with_columns(pl.col("Betriebstag").dt.week().alias("KW"))
    )
    return per_day


# ======================================
# Routen aus zlm + Kanten-Zählungen
# ======================================
def route_counts(df_ev: pl.DataFrame, selected_trains: pl.DataFrame | None = None) -> pl.DataFrame:
    """
    Gibt Kanten-Zählungen zurück:
    prev_bst, bst, is_selected, n
    Wenn selected_trains=None → alles als is_selected=False.
    """
    df_trans = (
        df_ev.sort(["Betriebstag", "zn", "istzeit_dt"])
             .with_columns([
                 pl.col("bst").shift(1).over(["Betriebstag", "zn"]).alias("prev_bst"),
             ])
             .filter(pl.col("prev_bst").is_not_null())
             .select(["Betriebstag", "zn", "prev_bst", "bst"])
    )
    if selected_trains is not None:
        flags = selected_trains.with_columns(pl.lit(True).alias("is_selected"))
        df_trans = (
            df_trans.join(flags, on=["Betriebstag", "zn"], how="left")
                    .with_columns(pl.col("is_selected").fill_null(False))
        )
    else:
        df_trans = df_trans.with_columns(pl.lit(False).alias("is_selected"))

    return (
        df_trans.group_by(["prev_bst", "bst", "is_selected"])
                .agg(pl.len().alias("n"))
                .sort(["is_selected", "n"], descending=[True, True])
    )


# ================================
# Folium-Karte aus Kanten-Zählung
# ================================
def folium_map_from_counts(
    counts: pl.DataFrame,
    nodes_df: pl.DataFrame,
    *,
    outfile: Path,
    selected_color="#0a84ff",
    other_color="#999999",
    min_weight=1.0,
    max_weight=8.0,
):
    import folium

    # Node-Lookup
    nodes = {row["bst"]: (float(row["lat"]), float(row["lon"])) for row in nodes_df.iter_rows()}

    # Map-Zentrum
    lats = [v[0] for v in nodes.values()]
    lons = [v[1] for v in nodes.values()]
    center = (sum(lats)/len(lats), sum(lons)/len(lons)) if lats else (51.0, 10.0)

    m = folium.Map(location=center, zoom_start=7, control_scale=True, tiles="cartodbpositron")

    # Skalierung der Linienstärke
    n_max = counts["n"].max() if counts.height else 1
    def w(n):
        if n_max <= 1: return min_weight
        # log-Skalierung
        x = math.log10(1 + float(n)) / math.log10(1 + float(n_max))
        return min_weight + (max_weight - min_weight) * x

    # Layer
    fg_sel = folium.FeatureGroup(name="Auswahl", overlay=True, show=True)
    fg_oth = folium.FeatureGroup(name="Andere", overlay=True, show=True)

    for row in counts.iter_rows(named=True):
        u = row["prev_bst"]; v = row["bst"]; n = row["n"]; sel = row["is_selected"]
        if u not in nodes or v not in nodes:
            continue
        latlon = [nodes[u], nodes[v]]
        color = selected_color if sel else other_color
        folium.PolyLine(latlon, color=color, weight=w(n), opacity=0.8, tooltip=f"{u} → {v} | n={n}").add_to(fg_sel if sel else fg_oth)

    fg_sel.add_to(m); fg_oth.add_to(m)
    folium.LayerControl().add_to(m)
    m.save(str(outfile))
    return outfile


# example_usage.py
from pathlib import Path
import datetime as dt
import polars as pl

from analytics_bundle import (
    read_zlm_range, select_trains_by_bst, select_trains_by_zn, load_line_mapping, select_trains_by_line,
    daily_metrics_area, daily_metrics_simple, route_counts, folium_map_from_counts
)

cfg = get_config(wochenscharf=False)  # deine bestehende Funktion
tage, cfg = prepare_time_range(cfg)

zlm_root = Path(cfg["path_to_SQF_preprocessed"])
produkt  = cfg["produkt"]

# 1) Einlesen
df_ev = read_zlm_range(
    zlm_root, produkt, tage,
    separator=":",     # ggf. ";" bei Semikolon-CSV
    decimal_comma=True # ggf. False, wenn Punkt-Dezimal
)

# ========== A) Gebiet (BST) – vor/auf/nach + Karte ==========
auswahl_bst = cfg.get("auswahl_BST") or cfg.get("Auswahl_BST") or []
sel_trains_area = select_trains_by_bst(df_ev, auswahl_bst, selection_mode="any")  # oder "all"
per_day_area = daily_metrics_area(df_ev, sel_trains_area, ontime_sec=360)
per_day_area.write_csv(Path(cfg["path_to_data"]) / "area_metrics.csv")

# Karte: Routen der Auswahl vs. Andere
nodes_df = pl.read_csv("/pfad/zu/nodes.csv")  # bst,lat,lon
counts_area = route_counts(df_ev, sel_trains_area)
folium_map_from_counts(counts_area, nodes_df, outfile=Path(cfg["path_to_data"]) / "map_area.html")

# ========== B) Zugnummern – Auswahl vs. Andere (ohne Phasen) ==========
zugnummern = ["12345", "67890"]  # deine Auswahl
sel_trains_zn = select_trains_by_zn(df_ev, zugnummern)
per_day_zn = daily_metrics_simple(df_ev, sel_trains_zn, ontime_sec=360)
per_day_zn.write_csv(Path(cfg["path_to_data"]) / "zn_metrics.csv")
counts_zn = route_counts(df_ev, sel_trains_zn)
folium_map_from_counts(counts_zn, nodes_df, outfile=Path(cfg["path_to_data"]) / "map_zn.html")

# ========== C) Linien – Auswahl vs. Andere (ohne Phasen) ==========
map_df = load_line_mapping(Path("/pfad/zu/linien_mapping.csv"), zn_col="Zugnummer", line_col="Nr")
sel_trains_line = select_trains_by_line(df_ev, map_df, linien=["10", "20"])  # z.B. Linien 10 & 20
per_day_line = daily_metrics_simple(df_ev, sel_trains_line, ontime_sec=360)
per_day_line.write_csv(Path(cfg["path_to_data"]) / "line_metrics.csv")
counts_line = route_counts(df_ev, sel_trains_line)
folium_map_from_counts(counts_line, nodes_df, outfile=Path(cfg["path_to_data"]) / "map_line.html")