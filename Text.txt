# bst_clip_layers.py
# pip install pandas geopandas shapely requests rtree pyproj

from __future__ import annotations
import io, os, re, requests
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
from shapely.validation import make_valid

# ---------------------- Konstante ----------------------
BUNDESLAENDER_URL = (
    "https://raw.githubusercontent.com/isellsoap/deutschlandGeoJSON/master/2_bundeslaender/3_mittel.geojson"
)

# ---------- robuste Koordinaten-Parser ----------
LAT_RANGE = (45.0, 58.0)   # grob DE + Rand
LON_RANGE = (3.0, 20.0)
_num_re = re.compile(r"[-+]?\d+(?:[.,]\d+)?")

def _is_lat(x: float) -> bool: return LAT_RANGE[0] <= x <= LAT_RANGE[1]
def _is_lon(x: float) -> bool: return LON_RANGE[0] <= x <= LON_RANGE[1]

def parse_latlon(val):
    """Akzeptiert: '52.52,13.405' | '52.52 13.405' | '(52.52, 13.405)'
       | "('52.52','13.405')" | 'POINT (13.405 52.52)'.
       Liefert (lat, lon) oder None.
    """
    if pd.isna(val): return None
    if isinstance(val, (tuple, list)) and len(val) == 2:
        try:
            a = float(str(val[0]).replace(",", "."))
            b = float(str(val[1]).replace(",", "."))
        except ValueError:
            return None
    else:
        s = str(val).strip().strip('"').strip("'")
        nums = _num_re.findall(s)
        if len(nums) < 2: return None
        a = float(nums[0].replace(",", "."))
        b = float(nums[1].replace(",", "."))
    if _is_lat(a) and _is_lon(b): return (a, b)
    if _is_lon(a) and _is_lat(b): return (b, a)
    return None

# ---------- BST aus Strecken-CSV bauen ----------
def build_betriebsstellen(df: pd.DataFrame) -> pd.DataFrame:
    need = {"von","bis","von_latlon","bis_latlon"}
    miss = need - set(df.columns)
    if miss:
        raise ValueError(f"Fehlende Spalten in CSV: {miss}")

    a = df[["von","von_latlon"]].rename(columns={"von":"betriebsstelle","von_latlon":"latlon"})
    b = df[["bis","bis_latlon"]].rename(columns={"bis":"betriebsstelle","bis_latlon":"latlon"})
    long_df = pd.concat([a,b], ignore_index=True)

    coords = long_df["latlon"].apply(parse_latlon)
    long_df["lat"] = coords.apply(lambda t: t[0] if t else None)
    long_df["lon"] = coords.apply(lambda t: t[1] if t else None)
    long_df["betriebsstelle"] = long_df["betriebsstelle"].astype(str).str.strip()
    long_df = long_df.dropna(subset=["lat","lon"])
    if long_df.empty:
        raise ValueError("Keine gültigen Koordinaten geparst – prüfe *_latlon.")

    # Deduplizieren: häufigste Koordinate je BST
    def pick_coords(grp: pd.DataFrame):
        vc = grp[["lat","lon"]].round(6).value_counts()
        if not vc.empty:
            lat, lon = vc.index[0]
            return pd.Series({"lat": lat, "lon": lon})
        return pd.Series({"lat": grp["lat"].mean(), "lon": grp["lon"].mean()})

    bst = long_df.groupby("betriebsstelle", as_index=False).apply(pick_coords).reset_index(drop=True)
    return bst[["betriebsstelle","lat","lon"]]

# ---------- Bundesländer laden ----------
def load_bundeslaender() -> gpd.GeoDataFrame:
    try:
        gdf = gpd.read_file(BUNDESLAENDER_URL)
    except Exception:
        r = requests.get(BUNDESLAENDER_URL, timeout=30); r.raise_for_status()
        gdf = gpd.read_file(io.BytesIO(r.content))
    if gdf.crs is None: gdf.set_crs(epsg=4326, inplace=True)
    else: gdf = gdf.to_crs(epsg=4326)
    name = next((c for c in ["GEN","NAME","name","NAME_1","Bundesland"] if c in gdf.columns),
                [c for c in gdf.columns if c != gdf.geometry.name][0])
    gdf = gdf.rename(columns={name: "label"})
    return gdf[["label", gdf.geometry.name]]

# ---------- Netzstruktur/Region/Netzbezirk/Netz laden ----------
def load_netz_layer(path: str, layer: str) -> gpd.GeoDataFrame:
    """
    path: GeoJSON aus DB (enthält org_level_name/org_name)
    layer: 'region' | 'netzbezirk' | 'netz'
    Erkennt 25832-Koordinaten (Meter) automatisch, überschreibt ggf. CRS und
    transformiert danach nach 4326. Repariert ungültige Geometrien.
    """
    gdf = gpd.read_file(path)  # GeoJSON mit Polygonen
    # CRS-Heuristik: wenn Bounds >> 200, sind es Meter (typisch 25832)
    minx, miny, maxx, maxy = gdf.total_bounds
    if gdf.crs is None or (maxx > 200 or maxy > 200):
        gdf.set_crs(epsg=25832, allow_override=True, inplace=True)

    lvl_col  = next((c for c in gdf.columns if c.lower()=="org_level_name"), None)
    name_col = next((c for c in gdf.columns if c.lower()=="org_name"), None)
    if not lvl_col or not name_col:
        raise ValueError("In der Netz-GeoJSON fehlen 'org_level_name' und/oder 'org_name'.")

    target = {"region":"Region", "netzbezirk":"Netzbezirk", "netz":"Netz"}[layer]
    sub = gdf[gdf[lvl_col].astype(str).str.casefold() == target.casefold()].copy()
    if sub.empty:
        raise ValueError(f"Keine Features mit org_level_name='{target}' in {path}.")

    # Geometrien reparieren (falls nötig), dann nach WGS84
    invalid = (~sub.is_valid).sum()
    if invalid:
        sub["geometry"] = sub.geometry.apply(make_valid)

    sub = sub.to_crs(epsg=4326).rename(columns={name_col: "label"})
    return sub[["label", sub.geometry.name]]

# ---------- Zuschneiden mit Fallback ----------
def clip_bst_to_polygons(bst: pd.DataFrame, poly_wgs84: gpd.GeoDataFrame, out_label: str) -> pd.DataFrame:
    points = gpd.GeoDataFrame(
        bst.copy(),
        geometry=[Point(xy) for xy in zip(bst["lon"], bst["lat"])],
        crs="EPSG:4326"
    )

    # 1) Intersects-Join
    joined = gpd.sjoin(
        points,
        poly_wgs84[["label", poly_wgs84.geometry.name]],
        how="left", predicate="intersects"
    ).rename(columns={"label": out_label})

    # 2) Nearest-Fallback (metrisch) – Index-sicher
    missing_idx = joined.index[joined[out_label].isna()].unique()
    if len(missing_idx) > 0:
        pts_32  = points.to_crs(epsg=25832)
        poly_32 = poly_wgs84.to_crs(epsg=25832)

        nearest = gpd.sjoin_nearest(
            pts_32.loc[missing_idx],
            poly_32[["label", poly_32.geometry.name]],
            how="left",
            distance_col="dist_m"
        )
        joined.loc[nearest.index, out_label] = nearest["label"].values

    out = joined.drop(columns=["geometry"])[["betriebsstelle","lat","lon", out_label]]
    return out

# ========================= MAIN =========================
if __name__ == "__main__":
    # --- HIER EINSTELLEN ---
    INPUT_CSV   = "trassenfinder_verbindungen.csv"  # Strecken-CSV mit von/bis und *_latlon
    NETZ_JSON   = "netzstruktur.geojson"            # deine Netzstruktur (für region/netzbezirk/netz)
    LAYER       = "netzbezirk"                      # "bundesland" | "region" | "netzbezirk" | "netz"
    OUTPUT_CSV  = f"bst_mit_{LAYER}.csv"
    # ------------------------

    df  = pd.read_csv(INPUT_CSV)
    bst = build_betriebsstellen(df)

    if LAYER == "bundesland":
        poly = load_bundeslaender()
        out_label = "bundesland"
    else:
        poly = load_netz_layer(NETZ_JSON, LAYER)
        out_label = LAYER  # region | netzbezirk | netz

    res = clip_bst_to_polygons(bst, poly, out_label)
    res.sort_values([out_label, "betriebsstelle"], inplace=True, na_position="last")
    res.to_csv(OUTPUT_CSV, index=False, encoding="utf-8")
    print(f"Fertig: {len(res)} BST mit {out_label} → {OUTPUT_CSV}")